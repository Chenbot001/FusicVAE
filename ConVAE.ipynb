{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE176 Final Project VAE\n",
    "### Eric Chen\n",
    "### A16420083\n",
    "\n",
    "This project attempt to train a Variational Encoder which generates Mel Spectrograms for music synthesis. We train the model on a dataset of music from two distinct genres (traditional Chinese and electronic) and finetune it using the music from one particular artist. We hope that the synthesized sample can exhibit features of both genres in the style of the desired artist.\n",
    "\n",
    "**Disclaimer: The soundtracks utilized in this project are the property of their respective owners and copyright holders. I do not claim any ownership over the music used for model training. This project is strictly for educational and research purposes only, with no commercial intent or application. All music and related materials remain the intellectual property of their original creators.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "init_mem = torch.cuda.memory_allocated()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecDataset(Dataset):\n",
    "    def __init__(self, directory, transform = None):\n",
    "        self.file_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.npy')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel_spec = np.load(self.file_paths[idx])\n",
    "\n",
    "        spec_min = np.min(mel_spec)\n",
    "        spec_max = np.max(mel_spec)\n",
    "        mel_spec_norm = (mel_spec - spec_min) / (spec_max - spec_min + 1e-6)\n",
    "\n",
    "        if self.transform:\n",
    "            mel_spec_norm = self.transform(mel_spec_norm)\n",
    "        return mel_spec_norm, spec_min, spec_max\n",
    "\n",
    "class Trim(object):\n",
    "    def __init__(self, new_width):\n",
    "        self.new_width = new_width\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor[:,:,:self.new_width]\n",
    "    \n",
    "spec_path = 'C:/Eric/UCSD/ECE/ECE176_Final/dataset/pre_training_data/spectrograms'\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = MelSpecDataset(spec_path, transform=transform)\n",
    "\n",
    "# 8/1/1 split\n",
    "train_len = int(0.8 * len(dataset))\n",
    "valid_len = int(0.1 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "\n",
    "# Split the dataset\n",
    "train_set, valid_set, test_set = random_split(dataset, [train_len, valid_len, test_len])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated to model: 285.8125 Mb\n",
      "Model Parameters 74259529\n"
     ]
    }
   ],
   "source": [
    "class ResizeConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, mode='nearest'):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
    "        #nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class encBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = in_channels*stride\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        #nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        #nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride == 1:\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class decBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = int(in_channels/stride)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        #nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride == 1:\n",
    "            self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            #nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "            self.bn1 = nn.BatchNorm2d(channels)\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.conv1 = ResizeConv2d(in_channels, channels, kernel_size=3, scale_factor=stride)\n",
    "            self.bn1 = nn.BatchNorm2d(channels)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                ResizeConv2d(in_channels, channels, kernel_size=3, scale_factor=stride),\n",
    "                nn.BatchNorm2d(channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn2(self.conv2(x)))\n",
    "        out = self.bn1(self.conv1(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class RN18E(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], latent_dim=100, nc=1):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv1 = nn.Conv2d(nc, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        #nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(encBlock, 64, num_Blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(encBlock, 128, num_Blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(encBlock, 256, num_Blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(encBlock, 512, num_Blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*8*41, 2*latent_dim)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_layer(self, encBlock, planes, num_Blocks, stride):\n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers += [encBlock(self.in_planes, stride)]\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        mu = x[:, :self.latent_dim]\n",
    "        logvar = x[:, self.latent_dim:]\n",
    "        return mu, logvar\n",
    "\n",
    "class RN18D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_Blocks=[2,2,2,2], latent_dim=100, nc=1):\n",
    "        super().__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.linear = nn.Linear(latent_dim, 512*8*41)\n",
    "\n",
    "        self.layer4 = self._make_layer(decBlock, 256, num_Blocks[3], stride=2)\n",
    "        self.layer3 = self._make_layer(decBlock, 128, num_Blocks[2], stride=2)\n",
    "        self.layer2 = self._make_layer(decBlock, 64, num_Blocks[1], stride=2)\n",
    "        self.layer1 = self._make_layer(decBlock, 64, num_Blocks[0], stride=1)\n",
    "        self.conv1 = ResizeConv2d(64, nc, kernel_size=3, scale_factor=4)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, decBlock, planes, num_Blocks, stride):\n",
    "        strides = [stride] + [1]*(num_Blocks-1)\n",
    "        layers = []\n",
    "        for stride in reversed(strides):\n",
    "            layers += [decBlock(self.in_planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.linear(z)\n",
    "        x = x.view(x.size(0), 512, 8, 41)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.sigmoid(self.conv1(x))\n",
    "        x = x.view(x.size(0), 1, 256, -1)\n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = RN18E(latent_dim=latent_dim)\n",
    "        self.decoder = RN18D(latent_dim=latent_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        #zero pad or trim to the right\n",
    "        if x.size(3) > x_recon.size(3):\n",
    "            pad = x.size(3) - x_recon.size(3)\n",
    "            x_recon = F.pad(x_recon, (0, pad, 0, 0))\n",
    "        elif x.size(3) < x_recon.size(3):\n",
    "            x_recon = x_recon[:,:,:,:x.size(3)]\n",
    "            \n",
    "        return x_recon, mu, logvar\n",
    "    \n",
    "    def loss(self, x, x_recon, mu, log_var):\n",
    "\n",
    "        #recontruction loss\n",
    "        #bce_loss = F.binary_cross_entropy_with_logits(x_recon, x, reduction='sum')\n",
    "        mse_loss = F.mse_loss(x_recon, x, reduction='sum')\n",
    "\n",
    "        #kl divergence loss\n",
    "        kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) + 1e-10 - (log_var + 1e-10).exp())\n",
    "\n",
    "        return mse_loss + kl_loss\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(logvar / 2)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return epsilon * std + mu\n",
    "    \n",
    "    def sample(self, mu, logvar): \n",
    "        z = self.reparameterize(mu, logvar) \n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "    \n",
    "def he_initialization(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Create the model\n",
    "torch.cuda.empty_cache()\n",
    "latent_dim = 100\n",
    "vae = VAE(latent_dim).to(device)\n",
    "vae.apply(he_initialization)\n",
    "\n",
    "#model summary\n",
    "final_mem = torch.cuda.memory_allocated()\n",
    "model_mem = final_mem - init_mem\n",
    "model_memory_mb = model_mem / (1024 ** 2)\n",
    "print(f'Memory allocated to model: {model_memory_mb} Mb')\n",
    "num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
    "print(f'Model Parameters {num_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Valiate and Test Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader,epoch, print_freq, optimizer):\n",
    "    avg_losses = []   # Avg. losses.\n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs = data[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, log_var = model(inputs)\n",
    "        #print('recon',recon.size())    #for debugging\n",
    "        #print('input',inputs.size())\n",
    "        #print(recon.min(), recon.max())\n",
    "        #break\n",
    "        loss = vae.loss(inputs, recon, mu, log_var)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        avg_losses.append(loss.item() / len(inputs))\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(f'Epoch:{epoch} [{i}/{len(train_loader)}] Loss: {avg_losses[-1]}')\n",
    "\n",
    "    epoch_train_loss = sum(avg_losses) / len(avg_losses)\n",
    "    return vae, epoch_train_loss\n",
    "\n",
    "def validate_vae(model, valid_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(valid_loader, 0):\n",
    "            inputs = data[0].to(device)\n",
    "\n",
    "            recon, mu, log_var = model(inputs)\n",
    "\n",
    "            loss = model.loss(inputs, recon, mu, log_var)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(valid_loader.dataset)\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def test_vae(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(valid_loader, 0):\n",
    "            inputs = data[0].to(device)\n",
    "\n",
    "            recon, mu, log_var = model(inputs)\n",
    "\n",
    "            loss = model.loss(inputs, recon, mu, log_var)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# train the model for n epochs\n",
    "epochs = 100\n",
    "# model initialization  \n",
    "print_freq = 100  # Print frequency.\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.00001)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "vae.train()\n",
    "training_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    vae, training_loss = train_vae(vae, train_loader, epoch, print_freq, optimizer)\n",
    "    training_losses.append(training_loss)\n",
    "    print(f'Epoch {epoch} Training Loss: {training_loss:.4f}')\n",
    "    valid_loss = validate_vae(vae, valid_loader)\n",
    "    print(f'Epoch {epoch} Validation Loss: {valid_loss:.4f}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(training_losses, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "test_loss = test_vae(vae, test_loader)\n",
    "print(f'Test Accuracy: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "#generate samples\n",
    "def generate_sample(model, latent_dim):\n",
    "    mu = torch.randn([1, latent_dim]).to(device) \n",
    "    logvar = torch.randn([1, latent_dim]).to(device)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        sample = model.sample(mu, logvar)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Assuming your model and latent_dim are defined\n",
    "melspec_gen = generate_sample(vae, latent_dim)\n",
    "# plot and play the generated sample\n",
    "melspec_gen = melspec_gen.detach().cpu().numpy().squeeze()\n",
    "scaled_melspec_gen = melspec_gen*5000\n",
    "mel_spec_db = librosa.power_to_db(scaled_melspec_gen, ref=np.max)\n",
    "\n",
    "# Convert melspec to wave\n",
    "audio = librosa.feature.inverse.mel_to_audio(scaled_melspec_gen, sr=44100, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mel_spec_db, x_axis='time', y_axis='mel', sr=44100, fmax=8000)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Playing: Generated sample from VAE...\")\n",
    "print(f\"MelSpec Dimensions: {melspec_gen.shape}\")\n",
    "Audio(audio, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = vae.state_dict()\n",
    "optimizer_state_dict = optimizer.state_dict()\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_state_dict,\n",
    "    'optimizer_state_dict': optimizer_state_dict,\n",
    "}, 'msVAE.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "finetuning_path = 'C:/Eric/UCSD/ECE/ECE176_Final/dataset/hoyo/spectrograms'\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = MelSpecDataset(finetuning_path, transform=transform)\n",
    "\n",
    "# 8/1/1 split\n",
    "train_len = int(0.8 * len(dataset))\n",
    "valid_len = int(0.1 * len(dataset))\n",
    "test_len = len(dataset) - train_len - valid_len\n",
    "\n",
    "# Split the dataset\n",
    "train_set, valid_set, test_set = random_split(dataset, [train_len, valid_len, test_len])\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=8, shuffle=True)\n",
    "\n",
    "# train the model for n epochs\n",
    "epochs = 50  \n",
    "print_freq = 100  # Print frequency.\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-5)\n",
    "\n",
    "#load model\n",
    "checkpoint = torch.load('msVAE_tuned.pth')\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    vae, training_loss = train_vae(vae, train_loader, epoch, print_freq, optimizer)\n",
    "    training_losses.append(training_loss)\n",
    "    print(f'Epoch {epoch} Training Loss: {training_loss:.4f}')\n",
    "    valid_loss = validate_vae(vae, valid_loader)\n",
    "    print(f'Epoch {epoch} Validation Loss: {valid_loss:.4f}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = vae.state_dict()\n",
    "optimizer_state_dict = optimizer.state_dict()\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model_state_dict,\n",
    "    'optimizer_state_dict': optimizer_state_dict,\n",
    "}, 'msVAE_final.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
